{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまで我々が見てきたNNは，フィードフォワードと呼ばれるネットワークで，流れが1方向でしかなかった.  \n",
    "フィードフォワードでは時系列データをうまく扱うことができない．  \n",
    "そこでリカレントニューラルネットワーク(RNN)の出番である．  \n",
    "本章では，フィードフォワードの問題点を指摘し，RNNがその問題を解決することを示す．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率と言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vecを確率の視点から眺める\n",
    "\n",
    "コーパス$w_1, w_2, ... w_T$が与えられているとき，$w_t$がターゲットとなる確率は，コンテキスト$w_{t-1}, w{t+1}$を使って\n",
    "$$ P(w_t | w_{t-1}, w_{t+1})$$\n",
    "と書ける．  \n",
    "ここで，コンテキストの窓を非対称にして全て左側にコンテキストがあるとすると，$w_t$がターゲットとなる確率は\n",
    "$$ P(w_t | w_{t-2}, w_{t-1})$$\n",
    "このとき，CBOWモデルが扱う損失関数は\n",
    "$$ L=-\\log P(w_t|w_{t-2}, w_{t-1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 言語モデル\n",
    "言語モデルは，単語の並びがどれだけ自然であるかを確率で評価する．  \n",
    "例えば，\n",
    "- you say goodbye -> 0.092\n",
    "- you say good die -> 0.000000000000032  \n",
    "\n",
    "$ w_1, ..., w_m $ という順序で単語が出現する確率は，同時確率 $ P(w_1, ..., w_m) $ で表される．  \n",
    "これを事後確率と確率の乗法定理 $P(A, B) = P(A|B)P(B)$ を使って分解すると　　\n",
    "$$ P(w_1, ..., w_m) = P(w_m|w_1, ... w_{m-1})P(w_{m-1}|w_1, ... w_{m-2}) ... P(w_3|w_1, w_2)P(w_2|w_1)P(w_1)$$  \n",
    "$$ = \\prod_{t=1}^{m} P(w_t|w_1, ..., w_{t-1})$$\n",
    "\n",
    "確率の乗法定理は，「AとBが両方同時に起こる確率 $P(A,B)$」は，「Bが起こる確率$P(B)$」と「Bが起こったあとにAが起きる確率P(A|B)」を掛け合わせたものである． \n",
    "また，$P(A, B) = P(B|A)P(A)$と書くこともできる．  \n",
    "ここで注目すべきは，事後確率が対象の単語より左の全ての単語をコンテキストとした時の確率ということである．  \n",
    "また， $P(w_t|w_1, ... w_{t-1})$を表すモデルは，条件付き言語モデルと呼ばれる．これを言語モデルと呼ぶ場合も多く見られる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOWモデルを言語モデルに？\n",
    "CBOWモデルを無理やり言語モデルに適用するには，コンテキストのサイズをある値に限定することで近似的に表すことができる．  \n",
    "$$ P(w_1, ..., w_m) = \\prod_{t=1}^{m} P(w_t|w_1, ..., w_{t-1}) \\approx \\prod_{t=1}^{m} P(w_t|w_{t-2}, w_{t-1}) $$\n",
    "  \n",
    "マルコフ性  \n",
    "未来の状態が現在の状態だけに依存して決まること．  \n",
    "ここで，ある事象の確率がその直前のN個の事象だけに依存するとき，これを「N階マルコフ連鎖」という． 　\n",
    "今は直前の2つに依存して次の単語が決まるので，2階マルコフ連鎖と呼べる．  \n",
    "  \n",
    "コンテキストのサイズは任意に設定できるが，固定する必要があるところに問題がある．  \n",
    "例えば，コンテキストのサイズが10だが答えとなるTomなどの固有名詞が18個前にしかない時，この推論問題に答えることはできない．  \n",
    "コンテキストを20にしたりすれば答えることはできる．  \n",
    "  \n",
    "しかし次にはコンテキスト内の単語の並びが無視されるという問題がある．  \n",
    "例えば，(you,say)というコンテキストと(say,you)というコンテキストが同じものとして表される．  \n",
    "これは，CBOWモデルの中間層を各コンテキストが共有しているために起きる．  \n",
    "そこで，コンテキストごとに中間層を設けることで，すなわち複数の中間層を「連結(contcatenate)」することでこの問題に対処できる．  \n",
    "しかし，そのようにするとコンテキストのサイズに比例して重みパラメータが増大してしまう．  \n",
    "\n",
    "これらの問題を解決するのがRNNである．  \n",
    "RNNは，コンテキストがどれだけ長くても，そのコンテキストの情報を記憶するメカニズムを持つ．  \n",
    "  \n",
    "ちなみに，実はword2vecの方が後に提案されている．  \n",
    "RNNによる言語モデルでも単語の分散表現を獲得できるのだが，新たな語彙の追加しやすさや単語の分散表現の質の向上のためword2vecが提案された．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNとは\n",
    "Recurrent Neural Networkは日本語では「再起ニューラルネットワーク」や「循環ニューラルネットワーク」と呼ばれる．  \n",
    "これに対してRecursive Neural Networkというものもあるが，こちらは主に木構造のデータを処理するためのネットワークで，RNNとは別物である．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 循環するニューラルネットワーク\n",
    "RNNの特徴は，閉路を持つことである．  \n",
    "入力データを$(x_0, x_1, ... x_t, ...)$として， 出力データ$(h_0, h_1, ... h_t, ...)$ を自分にも入力する，すなわち閉路を持つ層をRNNレイヤと名付ける．　　\n",
    "ここで，　$x_t$や$h_t$はベクトルを想定する．例えば，ある単語の分散表現を$x_t$としたりする．  \n",
    "また，これまではデータが左から右へ流れていたが，以降は左右方向にレイヤが展開されるため，紙面の都合上，下から上へデータが流れるように描画される．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ループの展開\n",
    "RNNレイヤは自身に出力データを流していたが，これを同じレイヤの別のRNNレイヤに流すことで，ループを展開する．  \n",
    "左から右へ，同じレイヤのRNNレイヤが並び，その順が時系列の順番になっている．　　\n",
    "その出力が，左から$h_0, h_1, ... h_t$となる．  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
