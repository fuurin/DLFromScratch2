{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前章で見たRNNは「シンプルなRNN」や「エルマン」と呼ばれ，時系列データの彫金お依存関係をうまく学習することができない問題点があった．  \n",
    "最近ではRNNという言葉が使われるときにはLSTMであることが多く見受けられる．  \n",
    "LSTMやGRUには「ゲート」と呼ばれる仕組みを持ち，長期的な依存関係を学習することができるようになっている．  \n",
    "<br>\n",
    "この章では「ゲート付きRNN」をテーマにLSTMを使って言語モデルを作り，実際のデータでうまく学習できる事を示す．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNの問題点\n",
    "RNNはBPTT（Backpropergation Through Time)において勾配消失もしくは勾配爆発が起こるため，長期記憶を苦手としている．  \n",
    "RNNが長期記憶を苦手とする理由を実例を使って見ていく．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNの復習\n",
    "RNNレイヤはループする経路を持ち，展開すると横に長く伸びるネットワークになる．  \n",
    "RNNレイヤは時系列データ$x_1, x_2, ... x_t$を入力として持ち$h_1, h_2, ..., h_t$を出力する．  \n",
    "この$h_t$はRNNレイヤの**隠れ状態**と呼ばれ，過去からの情報が記憶されており，各時刻におけるRNNレイヤは，一つ前の時刻の隠れ状態を利用する．  \n",
    "$x_t, h_{t-1}$から$h_t$を出力する式は以下のようになり，この式にしたがってRNNレイヤを構成する．\n",
    "$$h_t = \\tanh( h_{t-1} W_h + x_t W_x+ b ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配消失もしくは勾配爆発\n",
    "前章のRNNLMのような言語モデルが行うことは，これまでに与えられた単語から次に出現する単語を予測すること．  \n",
    "例えば，\n",
    "    <div style=\"text-align: center\">Tom was watching TV in his room. Mary came into the room. Mary said hi to [?]</div>\n",
    "    \n",
    "という文章について，[?]に入る単語はTomになる．  \n",
    "RNNLMに正解ラベルとしてTomという単語が与えられたとき，勾配がどのように伝播するかを考えてみる．  \n",
    "本来，勾配には学習すべき意味のある情報が入っており，過去に向かって伝わっていく.  \n",
    "しかし，もしこの勾配が途中で弱まってしまったら，過去にいくほど重みパラメータは更新されなくなってしまう．  \n",
    "残念ながら，シンプルなRNNでは時間を遡るにしたがって勾配が小さくなっていく(勾配消失)もしくは無駄に大きくなっていく(勾配爆発)がほとんどである．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配消失もしくは勾配爆発の原因\n",
    "RNNレイヤの時間方向だけの勾配の伝播だけに着目してみる  \n",
    "RNNレイヤの活性化関数であるtanhとtanhの微分をそれぞれグラフにしてみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "x = np.arange(-5, 5, 0.01)\n",
    "tanh = np.array([math.tanh(x_i) for x_i in x])\n",
    "tanh_prime = 1 - pow(tanh, 2)\n",
    "plt.plot(x, tanh, label=\"tanh(x)\")\n",
    "plt.plot(x, tanh_prime, label=\"dy/dx\")\n",
    "plt.legend() # matplotlibの凡例: https://qiita.com/matsui-k20xx/items/291400ed56a39ed63462\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このグラフの通り，dy/dxは最大値が1.0であり，そこから離れるごとに0に近づくので，このtanhノードを通るたびに勾配は小さくなっていく．  \n",
    "T回tanhを通過すればT回値が小さくなる． これが勾配消失の原因になっている．  \n",
    "活性化関数にReLUを使えば，ReLUの式$\\max(0, x)$を使って上流の勾配をそのまま下流に伝えることができ．勾配の劣化を起こさず性能が向上することがわかっている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にMatMulノードの逆伝播を見てみる．  \n",
    "MatMulノードの逆伝播では$dhW_h^\\top$による行列の積によって勾配が計算される．  \n",
    "この行列の席の計算では，毎回同じ重み$W_h$が使われることに注意する．  \n",
    "逆伝播の際の勾配の値は，MatMulノードを通るのに従ってどのように変化していくのかを観察してみる．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 2 # バッチサイズ\n",
    "H = 3 # 隠れ状態ベクトルの次元数\n",
    "T = 20 # 時系列データの長さ\n",
    "\n",
    "dh = np.ones((N, H)) # 上からやってくる勾配の計算\n",
    "# np.random.seed(3) # 再現性のため乱数のシードを固定\n",
    "Wh = np.random.randn(H, H) # 実験1,重みの初期値そのまま\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T) # MatMulノードの逆伝播の計算\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N # L2ノルムで行列全体の大きさの相場をスカラで表す\n",
    "    norm_list.append(norm)\n",
    "\n",
    "plt.scatter(range(T), norm_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフから分かるように，勾配の大きさは時間とともに指数的に増加する．これが**勾配爆発**である．  \n",
    "最終的にはオーバーフローを起こしてNaNのような値が発生してしまう．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Wh = np.random.randn(H, H) * 0.5 # 実験2, 重みの初期値に0.5をかける\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T) # MatMulノードの逆伝播の計算\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N # L2ノルムで行列全体の大きさの相場をスカラで表す\n",
    "    norm_list.append(norm)\n",
    "\n",
    "plt.scatter(range(T), norm_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆に，重みの初期値を小さくしてみると，**勾配消失**が発生する．  \n",
    "Tが大きいとき，$W_h$は今行列だが，例えばスカラであるとすると，$W_h$が1より大きいときには勾配爆発，小さいときには勾配消失が起きるというイメージになる.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W_h$が今のように行列の場合は，行列の「特異値」が勾配爆発，もしくは消失の指標となる．  \n",
    "行列の「特異値」は，データにどれだけ広がりがあるかをあらわし，これが1より大きいかどうかで，勾配の大きさの変化を予測することができる．  \n",
    "RNNの勾配消失/爆発については文献[30]に譲るが，特異値が1より大きい ⇦ 勾配爆発が発生 であり，ここでは必要条件となっていることに注意する．  \n",
    "しかし， 特異値が1より小さい ⇨ 勾配消失が発生 は成り立つ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配爆発への対策\n",
    "勾配クリッピング\n",
    "$$ \\rm{if} ||\\hat{g}|| \\geq threshold: \\hat{g} = \\frac {threshold} {||\\hat{g}||} \\hat{g} $$\n",
    "単純だが多くの場合うまくいくらしい  \n",
    "ここで$\\hat{g}$は取り扱う全ての重みを結合したもの．  \n",
    "例えば$W_1, W_2$をモデル内で使うなら，$||\\hat{g}|| = \\sqrt{||W_1|| + ||W_2||}$となる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0 # Threshold\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    # total_norm >= threshold  ==> total_norm+delta > threshold  ==> threshold/(total_norm+delta) < 1 ==> rate < 1\n",
    "    rate = max_norm / (total_norm + 1e-6) # ゼロディビジョン対策\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "clip_grads(grads, max_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 勾配消失とLSTM\n",
    "こっちはRNNレイヤのアーキテクチャを根本から変える必要がある．  \n",
    "ここで登場するのが「ゲート付きRNN」  \n",
    "本節ではLSTMにフォーカスし，勾配消失を起こさない(起こしにくい)ことを明らかにする．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMのインタフェース\n",
    "計算グラフ上で，RNNの$h_t$の計算をひとまとめにしてtanhノードとする．  \n",
    "<br>\n",
    "RNNとLSTMの違いは，**記憶セル**$c_{t-1}$(入力), と$c_{t}$(出力)を持っていること．  \n",
    "この記憶セルは隠れ状態ベクトル$h_t$と違って外部には見えず，その存在を外部から考える必要はない．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMレイヤの組み立て\n",
    "記憶セル$c_t$には，過去から時刻$t$までのLSTMに必要な記憶が格納されている．  \n",
    "この$c_t$は，$c_{t-1}$と$h_{t-1}$から，以降説明する計算によって算出され，次の時刻のLSTMレイヤへ直接出力される．  \n",
    "ここで，$c_t$と$h_t$は同じ要素数を持つ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「ゲート」とは門のことで，データの流れをコントロールする．  \n",
    "LSTMのゲートは開く/閉じるの二択ではなく，0~1.0の範囲でどれくらいの量の水を次へ流すかをコントロールする．  \n",
    "この「どれだけゲートを開くか」ということもデータから学習させ，専用の重みパラメータを更新する．  \n",
    "ゲートの開き具合を求めるときには，sigmoid関数を用いる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outputゲート\n",
    "今，LSTMの仕組みから，$h_t = \\tanh(c_t)$である．  \n",
    "この$\\tanh(c_t)$に対してゲートを適用する．  \n",
    "outputゲートの開き具合は，入力$x_t$と前の状態$h_{t-1}$から求める．  \n",
    "ゲートで使用する重みパラメータとバイアスについては，上添字にoutputの頭文字である$o$をつけて区別する．  \n",
    "また，シグモイド関数は$\\sigma()$で表す．  \n",
    "出力ゲートの値の式を以下に示す．  \n",
    "$$ o = \\sigma(x_t W_x^{(o)} + h_{t-1}W_h^{(o)} + b^{(o)}) $$\n",
    "このoutputゲートで行う計算を計算グラフ上では「σ」と表す．  \n",
    "Sigmoid関数を用いているため，$o$の各要素は0.0~1.0であり，ゲートの役割を持つことができる．  \n",
    "これにより，出力$h_t$は以下の式で計算される．  \n",
    "$$ h_t = o \\odot \\tanh(c_t) $$\n",
    "ここで$\\odot$はアダマール積と呼ばれ，同じ要素番号の要素同士の積をとる演算子である．  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forgetゲート\n",
    "次に，記憶セルに対して何を忘れるかを明示的に示してやる，forgetゲートを追加する．  \n",
    "forgetゲートの式は以下で表される．形はoutputゲートと同じで，別途専用の重みを使用する．  \n",
    "$$ \\rm{f} = \\sigma(x_t W_x^{(\\rm{f})} + h_{t-1}W_h^{(\\rm{f})} + b^{(\\rm{f})}) $$\n",
    "計算グラフ上では，forgetゲートも$\\sigma$を使って表される．  \n",
    "この$\\rm{f}$を使って，$c_t$は$c_{t-1}$より以下の式で計算される．  \n",
    "$$ c_t = c_{t-1} \\odot \\rm{f} $$\n",
    "現在，この$c_t$を使って，$h_t = \\tanh(c_t)$と計算されている.  これからまた色々ゲートを足していく．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新しい記憶セル\n",
    "forgetゲートで忘れるだけではなく，新しく覚えるべき情報を記憶セルに追加する．  \n",
    "$$ \\rm{g} = \\tanh(x_t W_x^{(\\rm{g})} + h_{t-1}W_h^{(\\rm{g})} + b^{(\\rm{g})}) $$\n",
    "計算グラフ上では，この新しい記憶セルは$\\tanh$を使って表される．  \n",
    "この$\\rm{g}$を$c_{t-1}$に加算することで新しい記憶が生まれる．  \n",
    "現在， $c_t = c_{t-1} \\odot \\rm{f} + \\rm{g} $, $h_t = o \\odot \\tanh(c_t) $である．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inputゲート\n",
    "最後に，新たに追加する情報$\\rm{g}$がどれだけ価値があるかを判断するinputゲートを追加する．  \n",
    "このinputゲートによって，何も考えずに新しい情報を追加するのではなく，追加する情報の取捨選択を行う．  \n",
    "$$ \\rm{i} = \\sigma(x_t W_x^{(\\rm{i})} + h_{t-1}W_h^{(\\rm{i})} + b^{(\\rm{i})}) $$\n",
    "計算グラフ上では，この新しい記憶セルも$\\sigma$を使って表される．\n",
    "そして，iとgの要素ごとの席の結果を記憶セルに追加する．  \n",
    "最終的に，\n",
    "$$ c_t = c_{t-1} \\odot \\rm{f} + \\rm{g} \\odot \\rm{i} $$\n",
    "$$ h_t = o \\odot \\tanh(c_t) $$\n",
    "という計算になる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでのLSTMは代表的なもので，他にも色々亜種がある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMの勾配の流れ\n",
    "上述のLSTMがなぜ勾配消失を起こさないのかを記憶セル$c$の逆伝播に注目して見てみる．  \n",
    "<br>\n",
    "$c_t$から$c_{t-1}$への逆伝播では，「＋」ノードと「×」ノードを通る．  \n",
    "「＋」ノードの逆伝播は，そのまま下流に上流のデータを流すので劣化が起きない．  \n",
    "「×」ノードの逆伝播は，今までは行列の積の逆伝播でデータの劣化が起きていたが，今はアダマール積の逆伝播である．  \n",
    "<br>\n",
    "「×」ノードでは，forgetゲートのゲート値がアダマール積でかけられている．  \n",
    "このforgetゲートのゲート値が大きければ下流に伝わる勾配は大きくなり，逆もまた然りとなる．  \n",
    "これは，forgetゲートが「忘れてはいけない」と導いた要素の勾配は劣化させず，逆もまた然り，ということである．  \n",
    "<br>\n",
    "以上の議論から，LSTMの記憶セルでは，重要とされた記憶を長期的に保持することができ，勾配消失が起きない/起きにくいことが分かる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMとは，Long short-term memoryの頭文字から来ている．  \n",
    "この言葉は，短期記憶(short-term memory)を長い(long)時間継続できることを意味する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMの実装\n",
    "まず1ステップの処理をLSTMクラスとして実装した後，Tステップ文をまとめて処理するクラスをTimeLSTMとして実装する．  \n",
    "まずはLSTMで行う4つのゲート計算を一つにまとめて計算を効率化するところから始める．  \n",
    "$$ \\begin{eqnarray*} \\\\\n",
    "\\rm{f} &=& \\sigma(x_tW_x^{(\\rm{f})} + h_{t-1}W_h^{(\\rm{f})} + b^{(\\rm{f})}) \\\\\n",
    "\\rm{g} &=& \\tanh(x_tW_x^{(\\rm{g})} + h_{t-1}W_h^{(\\rm{g})} + b^{(\\rm{g})}) \\\\\n",
    "\\rm{i} &=& \\sigma(x_tW_x^{(\\rm{i})} + h_{t-1}W_h^{(\\rm{i})} + b^{(\\rm{i})}) \\\\\n",
    "\\rm{o} &=& \\sigma(x_tW_x^{(\\rm{o})} + h_{t-1}W_h^{(\\rm{o})} + b^{(\\rm{o})}) \\\\\n",
    "c_t &=& \\rm{f} \\odot c_{t-1} + \\rm{g} \\odot \\rm{i} \\\\\n",
    "h_t &=& o \\odot \\tanh(c_t) \\\\\n",
    "\\end{eqnarray*} $$\n",
    "f, g, i, oの4つの式のσの中身に入っているアフィン変換の式を一つにまとめて計算できる．  \n",
    "$$ [\\begin{array} & f & g & i & o \\end{array}] = \n",
    "x_tW_x + h_{t-1}W_h + b = \n",
    "x_t [\\begin{array} & W_x^{(\\rm{f})} & W_x^{(\\rm{g})} & W_x^{(\\rm{i})} & W_x^{(\\rm{o})} \\end{array} ] + \n",
    "h_{t-1} [\\begin{array} & W_h^{(\\rm{f})} & W_h^{(\\rm{g})} & W_h^{(\\rm{i})} & W_h^{(\\rm{o})} \\end{array} ] + \n",
    "[\\begin{array} & b^{(\\rm{f})} & b^{(\\rm{g})} & b^{(\\rm{i})} & b^{(\\rm{o})} \\end{array} ] $$\n",
    "この4つの式を一気に計算し，記憶セルの計算の各所へ分散させるノードをsliceノードと呼び，計算グラフ上でsliceと表す．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import sigmoid\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None # 順伝播での中間結果の保持\n",
    "    \n",
    "    def forward(self, x, h_prev,  c_prev): # 前の時刻の記憶セルも引数にとる\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(x, Wx) * np.dot(h_prev, Wh) + b\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H] # 全行 H-1列まで\n",
    "        g = A[:, H:2*H] # 全行 H列から2*H-1列まで\n",
    "        i = A[:, 2 * H : 3 * H] # 全行 2＊H列から3＊H-1列まで\n",
    "        o = A[:, 3 * H:] # 全行 後ろからH列\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g) # 新しい記憶セルだけ出力ノードと同じtanhなので注意\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        tanh_c_next = np.tanh(c_next) # backwardで逆伝播の係数に使う\n",
    "        h_next = o * tanh_c_next\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, tanh_c_next, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, tanh_c_next, c_next = self.cache\n",
    "                \n",
    "        # 足し算の逆伝播は上流からの勾配をそのまま返す\n",
    "        # 掛け算の逆伝播は上流からの勾配に反対の入力をかけて返す\n",
    "        \n",
    "        # c_next方向とh_next方向に分岐しているノードを統合して下流に流すdsが必要\n",
    "        ds = dc_next + dh_next * o * (1 - tanh_c_next ** 2)\n",
    "        \n",
    "        df_affine = ds * c_prev\n",
    "        df = df_affine * f * (1 - f) # sigmoidの逆伝播\n",
    "        \n",
    "        dg_affine = ds * i\n",
    "        dg = dg_affine * (1 - g ** 2) # tanhの逆伝播\n",
    "        \n",
    "        di_affine = ds * g \n",
    "        di = di_affine * i * (1 - i) # sigmoidの逆伝播\n",
    "        \n",
    "        do_affine = dh_next * tanh_c_next\n",
    "        do = do_affine * o * (1 - o) # sigmoidの逆伝播\n",
    "        \n",
    "        # 4つ分の重みを水平方向に統合 (垂直方向はvstack)\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "                \n",
    "        # b方向へのrepeatの逆伝播\n",
    "        db = np.sum(dA, axis=0)\n",
    "        \n",
    "        # h_prev方向へのMatMulの逆伝播\n",
    "        dWh = h_prev.T @ dA\n",
    "        dh_prev = dA @ Wh.T\n",
    "        \n",
    "        # x方向へのMatMulの逆伝播\n",
    "        dWx = x.T @ dA\n",
    "        dx = dA @ Wx.T\n",
    "        \n",
    "        self.grads[0][...] = dWx # 3点リーダによって，浅いコピー(参照のコピー)ではなく深いコピー(値のコピー)を行う．\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        # 掛け算の微分は上流からの勾配に反対側の入力をかける\n",
    "        dc_prev = ds * f\n",
    "        \n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeLSTMの実装\n",
    "T個分の時系列データをLSTMでまとめて処理するレイヤを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = (np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b))\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or selh.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "        \n",
    "        # この辺はTimeRNNと一緒\n",
    "        # T個LSTMを作るのでbackwardでもT個回す\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        \n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            # 上の層と次の時刻の2つに分岐ノードが伸びているので，逆伝播ではこれらを加算してLSTMに渡す．\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx # この時刻tにxの勾配dxを追加， backwardでは全時刻分をTimeLSTMの返り値として一気に返す．\n",
    "            for i, grad in enumerate(layer.grads): # TimeRNN同様，全時刻の勾配の総和がTimeLSTMの勾配になる．\n",
    "                grads[i] += grad\n",
    "        \n",
    "        # 勾配値をディープコピー，外部化からアクセスできるようにする．\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        \n",
    "        # 最終的な時刻方向のTimeLSTMの勾配\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "    \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "    \n",
    "    # 訓練後，テストデータでのpredictのためにリセットする関数を用意\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMを使った言語モデル\n",
    "これまで実装したTimeLSTMを使って，言語モデル(文脈自然性判定器)を実装する.  \n",
    "前章のRNNを使った言語モデルのTimeRNNの層がTimeLSTMに入れ替わっただけ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import TimeEmbedding, TimeAffine, TimeSoftmaxWithLoss\n",
    "import pickle\n",
    "\n",
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # レイヤの作成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "        \n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "        \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "        \n",
    "    # 重みパラメータのセーブ/ロードはcommon.base_modelのBaseModelクラスを継承することでも実装できる．\n",
    "    # さらにBaseModelクラスではGPU対応やビット削減(16ビットの浮動小数点数で保存する)などの最適化が行われている．\n",
    "    \n",
    "    # 重みパラメータのセーブ\n",
    "    def save_param(self, file_name = 'Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "    \n",
    "    # 重みパラメータのロード\n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のTimeLSTMレイヤを使った言語モデルを使ってPTBデータセットの学習を行ってみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# 1. 勾配爆発を防ぐため，勾配クリッピングを適用して学習\\ntrainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20) # eval_interval: 20イテレーションごとにパープレキシティを評価\\ntrainer.plot(ylim=(0, 500)) # グラフ表示, パープレキシティは10000->135程度になり，大事なところのグラフの変化が小さくなってしまうのでy軸リミットを設定\\n\\n# 2. 最終的なパープレキシティをテストデータで評価\\nmodel.reset_state()\\nppl_test = eval_perplexity(model, corpus_test)\\nprint('test perplexity: ', ppl_test)\\n\\n# 3. パラメータの保存\\nmodel.save_params()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNNの隠れ状態のベクトルの要素数\n",
    "time_size = 35 # RNNを展開するサイズ\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# モデルの作成\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "\"\"\"\n",
    "# 1. 勾配爆発を防ぐため，勾配クリッピングを適用して学習\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20) # eval_interval: 20イテレーションごとにパープレキシティを評価\n",
    "trainer.plot(ylim=(0, 500)) # グラフ表示, パープレキシティは10000->135程度になり，大事なところのグラフの変化が小さくなってしまうのでy軸リミットを設定\n",
    "\n",
    "# 2. 最終的なパープレキシティをテストデータで評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)\n",
    "\n",
    "# 3. パラメータの保存\n",
    "model.save_params()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パープレキシティ（次の単語の選択肢の数の相場)は10000から学習によってだいたい135まで絞り込めるようになる．  \n",
    "これはあまり良い結果ではなく，2017年の最先端では60を下回っている．  \n",
    "以下ではさらにRNNLMの改善を行っていく．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNLMのさらなる改善\n",
    "改善すべきポイントを3つ説明，実装，精度向上の評価を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMレイヤでの多層化\n",
    "TimeLSTMのところをもう一層増やしてみる．\n",
    "ハイパーパラメータや解くべき問題の複雑さによって層の数は適宜決める必要がある．  \n",
    "PTBデータセットでは2～4層程度で良い結果が得られる．  \n",
    "<br>\n",
    "Google翻訳で使われるGNMTと呼ばれるモデルはLSTMを8層重ねたネットワークになっている．  \n",
    "取り組む問題が複雑で，大量のデータを用意できるとき，LSTMの層を深くすることで精度向上が期待できる．  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropoutによる過学習の抑制\n",
    "層を深くすることで表現力が豊かなモデルを作れるが，過学習の恐れがある．  \n",
    "過学習は，訓練データだけに対して高い正答率を示し，汎化能力が低くなっている状態のこと．  \n",
    "特にRNNは過学習を起こしやすく，対策のための研究が活発に行われている．  \n",
    "<br>\n",
    "過学習を防ぐには\n",
    "- 訓練データを増やす\n",
    "- モデルの複雑さを減らす\n",
    "- モデルの複雑化にペナルティを与える正則化を加える\n",
    "\n",
    "がまず考えられる．  \n",
    "<br>\n",
    "ここで扱うDropoutは，訓練時にレイヤ内のニューロンのいくつか(50%など)をランダムに無視して学習を行うことで，正則化の効果を得る．  \n",
    "ゼロから作るDLではDropoutレイヤを活性化関数(ReLUなど)の後に挿入する例を示し，それが過学習抑制に貢献することを示した．  \n",
    "LSTMでは，時系列方向にDropoutレイヤを挿入することがまず考え付くが，時間が進むのに比例してDropoutによるノイズが蓄積することになりよくない．  \n",
    "Dropoutは深さ方向への適用が吉．  \n",
    "<br>\n",
    "しかし，時間方向への正則化の研究も色々行われていて，例えば「変分Dropout(Variational Dropout)」が成功している．  \n",
    "変分Dropoutでは，同じ階層にあるDropoutでは共通のマスク(データを通す/通さないを決める2値のランダムパターン)を利用する．  \n",
    "これによって，情報の失われ方も固定されるので，通常のDropoutのような指数的な情報の損失を避けられる．  \n",
    "しかし本章では，通常のDropoutを実装する．  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重み共有\n",
    "Embeddingレイヤの重みとAffineレイヤの重みを共有(weight tying)することで学習するパラメータを大きく減らすことができ，精度も向上．  \n",
    "語彙数をV, 隠れ状態の次元数をHとすると，Embeddingレイヤの形状は(V, H), Affineレイヤの形状は(H, V)となる．  \n",
    "なので，Embeddingレイヤの重みを転置してAffineレイヤの重みとする．  \n",
    "<br>\n",
    "重み共有で精度が上がるのは，パラメータ数が減ることでモデルが単純になり，過学習を抑制できるからであると考えられる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## より良いRNNLMの実装\n",
    "以下の改善点をBetterRnnlmクラスとして実装する  \n",
    "- LSTMレイヤの多層化(ここでは2層)\n",
    "- Dropoutを使用\n",
    "- 重み共有(EmbeddingレイヤとAffineレイヤで重み共有)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
