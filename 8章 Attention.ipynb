{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attentionは効果的で重要なテクニック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "Attentionの仕組みを，seq2seq上で実装し，効果を確かめ，先端の応用について学んだ．  \n",
    "- Attention\n",
    "    - 翻訳元と翻訳先の単語があるように，時系列データ間には対応関係が存在することが多くある．  \n",
    "    - Attentionはその対応関係を学ぶ．  \n",
    "    - 対応関係を学ぶため，EncoderはLSTMの全ての時刻の出力データをDecoderに渡す．\n",
    "    - ベクトルの内積などによる類似度を使った重み付き和ベクトルによって，対応する単語を選択\n",
    "    - Attentionの処理は微分可能であるため，誤差逆伝播法で学習が可能\n",
    "    - 日付変換問題では，従来のseq2seqよりも格段に早く学習した．\n",
    "    - 算出される重み(確率)を可視化することで，入出力の対応関係を見ることができる．  \n",
    "- Attentionに関するテクニック\n",
    "    - 双方向RNN,双方向LSTM\n",
    "        - 逆方向のTimeLSTMと順方向のTimeLSTMの出力を結合\n",
    "    - Attentionレイヤを別のところに挟んでみる\n",
    "        - TimeLSTMの各時刻の間など\n",
    "    - seq2seqを深層化\n",
    "        - モデルの複雑化による過学習を防ぐため，Skipコネクションなどを利用する\n",
    "            - Skipコネクション：層の出力を層をまたいで先のノードに渡し，加算する\n",
    "- Attentionの応用\n",
    "    - Google Neural Machine Translation(GNMT)\n",
    "        - NNによって人間に近い精度を持ったGoogleの翻訳システム\n",
    "    - Transformer\n",
    "        - Self-Attention: 1つの時系列データを自分の入力と時系列の最初に渡す層\n",
    "        - LSTMではなくすべてをAttentionによって構成することで並列化が可能になり素早く学習できる\n",
    "        - GNMTを凌駕\n",
    "    - Neural Turing Machine(NTM)\n",
    "        - 外部メモリによるNNの拡張の研究例\n",
    "        - データからアルゴリズムを学習可能\n",
    "        - メモリの読み書きにAttentionが用いられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの仕組み\n",
    "「注意機構」(Attention mechanism)は，seq2seqに必要な情報へ注意を向けさせる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seqの問題点\n",
    "Encoderの出力するベクトルの長さが固定長だと，洋服がタンスからあふれだすように，いずれ限界が訪れる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoderの改良\n",
    "LSTMレイヤの隠れ状態ベクトルを「すべて」利用することで，入力される文章の長さに応じた情報を出力させる  \n",
    "全ての時刻の隠れ状態を返すか，最後の隠れ状態ベクトルだけを返すかは，KerasのRNN初期化時のreturn_sequencesなどで変更できる  \n",
    "<br>\n",
    "Encoderの出力するベクトルは入力された単語の数だけベクトルがあり，それぞれのベクトルは各単語に対応した情報を多く含む\n",
    "<br>\n",
    "吾輩 は 猫 で ある -> $hs$ \n",
    "<div style=\"text-align: center\">a b c d (「吾輩」要素強め)<br>\n",
    "e f g h<br>\n",
    "i j k l<br>\n",
    "m n o p<br>\n",
    "q r s t<br>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "ここまでのRNNは過去の情報しか見えないが，全体の情報をバランスよく含めたければ**双方向RNN**や**双方向LSTM**を使う．  \n",
    "ここでは，これまで通り単方向のLSTMを利用する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoderの改良1\n",
    "$hs$をDecoderで扱うとき，どの行がどの単語に対応しているかを学習させる．  \n",
    "単語やフレーズの対応関係を表す情報は**アライメント**と呼ばれる．  \n",
    "Attentionという技術は，アライメントのアイデアをseq2seqで自動で取り入れることに成功した．  \n",
    "このように，時系列データの変換のため，翻訳先と翻訳元の対応情報に注意を向けさせる仕組みを**Attention**と呼ぶ  \n",
    "<br>\n",
    "Attentionの仕組みを取り入れたDecoderは，LSTMへhsの最終行を渡すのと同時に，LSTMの各時刻からの出力と$hs$を受け取って何らかの計算をしたのち，Affine層へ出力するレイヤを設ける．  \n",
    "例えば，最初のLSTMが「I」を出力するとき，その層では$hs$から「吾輩」に対応するベクトルを選び出す操作を，その何らかの計算で行う．  \n",
    "しかし，選び出すという操作は基本的に微分ができないので，誤差逆伝搬法が使えない．  \n",
    "なので，$hs$のすべてを選び出し，各行に各単語の重要度(貢献度)となる重み$a$をかけることで選び出しを行う．  \n",
    "その重みをつけた各単語のベクトルの総和を**コンテキストベクトル**$c$として算出する．  \n",
    "例えば「吾輩」に相当するベクトルの重みが0.8などの大きな値であるとき，$hs$から算出されるコンテキストベクトルは「吾輩」のベクトルに近いベクトルになり，これがベクトルの選び出しに相当する操作で，微分も可能なものになっている．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hs (5, 4)\n",
      "[[ 0.08455291 -0.87183644 -1.44867529 -1.5531649 ]\n",
      " [-0.07343379  0.32136193 -2.26872536 -0.91245756]\n",
      " [ 1.44816106 -2.24923549 -0.85133341  0.58689905]\n",
      " [ 0.9343266   2.96251101 -0.24270997 -0.60812065]\n",
      " [-3.6929789  -0.09858716 -0.27716262  2.30943768]] \n",
      "\n",
      "a (5,)\n",
      "[0.8  0.1  0.03 0.05 0.02] \n",
      "\n",
      "ar (5, 4)\n",
      "[[0.8  0.8  0.8  0.8 ]\n",
      " [0.1  0.1  0.1  0.1 ]\n",
      " [0.03 0.03 0.03 0.03]\n",
      " [0.05 0.05 0.05 0.05]\n",
      " [0.02 0.02 0.02 0.02]] \n",
      "\n",
      "t (5, 4)\n",
      "[[ 0.06764233 -0.69746915 -1.15894023 -1.24253192]\n",
      " [-0.00734338  0.03213619 -0.22687254 -0.09124576]\n",
      " [ 0.04344483 -0.06747706 -0.02554     0.01760697]\n",
      " [ 0.04671633  0.14812555 -0.0121355  -0.03040603]\n",
      " [-0.07385958 -0.00197174 -0.00554325  0.04618875]] \n",
      "\n",
      "c (4,)\n",
      "[ 0.07660053 -0.58665622 -1.42903152 -1.30038798] \n",
      "\n",
      "行列の積による重み付き和\n",
      " [ 0.07660053 -0.58665622 -1.42903152 -1.30038798]\n"
     ]
    }
   ],
   "source": [
    "# コンテキストベクトルの算出\n",
    "T, H = 5,4 # 時系列の長さ，単語の隠れ層ベクトルの長さ\n",
    "hs = np.random.randn(T, H)\n",
    "print(\"hs\", hs.shape)\n",
    "print(hs, '\\n')\n",
    "\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "print(\"a\", a.shape)\n",
    "print(a, '\\n')\n",
    "\n",
    "ar = a.reshape(5, 1).repeat(H, axis=1) # 縦にして列方向へ展開，repeatいらないが，あとでrepeatの逆伝搬が必要なことを明示的にしたい．\n",
    "print(\"ar\", ar.shape) # (5, 4)\n",
    "print(ar, '\\n')\n",
    "\n",
    "t = hs * ar\n",
    "print(\"t\", t.shape) # (5, 4)\n",
    "print(t, '\\n')\n",
    "\n",
    "c = np.sum(t, axis=0) # ex.(X, Y, Z) のaxis=1で和を取ると，(X, Z)のように，id=1が消える\n",
    "print(\"c\", c.shape) # (4,)\n",
    "print(c, '\\n')\n",
    "\n",
    "# このような重み付き和の計算は，\n",
    "print(\"行列の積による重み付き和\\n\", a @ hs)\n",
    "# で行うこともできるが，バッチ処理ができない．  \n",
    "# その場合は，np.tensordotやnp.einsumを使うことになるが，ここではわかりやすさを優先してrepeatとsumを使う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hs (10, 5, 4)\n",
      "a (10, 5)\n",
      "ar (10, 5, 4)\n",
      "c (10, 4)\n",
      "[[ 0.60845087  5.98335102 -0.95877552  4.79154436]\n",
      " [-1.53182497  0.9250463  -3.88166203 -0.22836525]\n",
      " [ 2.92962544 -1.89501897  1.55933496  1.93830043]\n",
      " [-1.8490767   3.68555886 -2.66606838  0.16189415]\n",
      " [ 3.48944599 -4.40056372 -3.02395524 -0.56076369]\n",
      " [-0.47409319 -1.37706059  1.04667613 -1.01430008]\n",
      " [ 6.36342932  4.46393646  2.93700728 -8.03814722]\n",
      " [ 0.04809043 -2.36168177 -2.20928418 -0.4079501 ]\n",
      " [ 0.0098605  -1.94946884 -0.90309364  3.24999538]\n",
      " [ 0.82275756 -0.75207128 -0.52226468  0.9926366 ]]\n"
     ]
    }
   ],
   "source": [
    "# バッチ処理版の重み付き和\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "print(\"hs\", hs.shape)\n",
    "\n",
    "a = np.random.randn(N, T) # 各単語への重み\n",
    "print(\"a\", a.shape)\n",
    "\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2) # 各単語への重みを隠れベクトルの方向(チャネル方向)へ展開\n",
    "print(\"ar\", ar.shape)\n",
    "\n",
    "t = hs * ar\n",
    "c = np.sum(t, axis=1) # 単語の重み＝各チャネルの重さの総和\n",
    "\n",
    "print(\"c\", c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重み付き和の層をWeightSumクラスとして実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], [] # 学習に関するパラメータは持たない\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        t = hs * ar\n",
    "        \n",
    "        c = np.sum(t, axis=1)\n",
    "        self.cache = (hs, ar)\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1) # sum の逆伝播\n",
    "        dhs = dt * ar\n",
    "        dar = dt * hs\n",
    "        da = np.sum(dar, axis=2) # repeatの逆伝播\n",
    "        \n",
    "        return dhs, da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoderの改良2\n",
    "コンテキストベクトルを計算するための重み$a$は，$hs$の各行とdecoderの各時刻のLSTMが出力する単語ベクトルとの類似度で求める．  \n",
    "類似度はここではベクトルの内積(2つのベクトルがどれだけ同じ方向を向いているか,正射影の重なりの大きさの総和)を利用する．  \n",
    "$$ a \\cdot b = a_1b_1 + a_2b_2 + ... + a_nb_n $$\n",
    "さらにこの内積をSoftmax関数で正規化することで，総和が1.0の$a$になる．\n",
    "$$ y_t = \\frac{exp(s_t)}{\\sum_{i=1}^{N} exp(s_i)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t (10, 5, 4)\n",
      "s (10, 5)\n",
      "a (10, 5)\n"
     ]
    }
   ],
   "source": [
    "# aの計算\n",
    "\n",
    "from common.layers import Softmax\n",
    "\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "\n",
    "hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "# hr = h.reshape(N, 1, H) # ブロードキャストの場合\n",
    "\n",
    "t = hs * hr\n",
    "print(\"t\", t.shape)\n",
    "\n",
    "s = np.sum(t, axis=2)\n",
    "print(\"s\", s.shape)\n",
    "\n",
    "softmax = Softmax()\n",
    "a = softmax.forward(s)\n",
    "print(\"a\", a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a$を$hs$と$h$から計算するためのレイヤをAttentionWeightクラスとして実装する，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeight:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        \n",
    "        a = self.softmax.forward(s)\n",
    "        \n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "    \n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "        \n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoderの改良3\n",
    "Attention WeightレイヤとWeight Sumレイヤを組み合わせ，Attentionレイヤを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weights = None # 各単語の重みをあとで参照\n",
    "    \n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        c = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return c\n",
    "    \n",
    "    def backward(self, dc):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dc)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述の，「何らかの計算」の所にはこのAttentionレイヤが入る．  \n",
    "前章のDecoderに対してAttentionの情報を追加することになる．  \n",
    "TimeLSTM層の出力とAttentionの出力を「連結」してAffineレイヤに入力する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでAttentionレイヤができたので，時系列方向にAttentionレイヤを広げたTimeAttentionレイヤを実装する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "    \n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:, t, :])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weights)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs # 分岐ノードの逆伝播は足し算\n",
    "            dhs_dec[:, t, :] = dh\n",
    "        \n",
    "        return dhs_enc, dhs_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention付きseq2seqの実装\n",
    "AttentionEncoder, AttentionDecoder, AttentionSeq2seqを実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentionEncoderの実装\n",
    "扱う隠れベクトルが最後だけでなく全ての時刻におけるベクトルになっただけなので，Encoderを継承する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from ch07.seq2seq import Encoder, Seq2seq\n",
    "\n",
    "class AttentionEncoder(Encoder):\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentionDecoderの実装\n",
    "TimeAffineレイヤとTimeLSTMレイヤの間にTimeAttentionレイヤが入る．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(2 * H, V) / np.sqrt(2 * H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.attention = TimeAttention() # 普通のDecoderからの改良点\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:, -1]\n",
    "        self.lstm.set_state(h)\n",
    "        \n",
    "        out = self.embed.forward(xs)\n",
    "        dec_hs = self.lstm.forward(out)\n",
    "        c = self.attention.forward(enc_hs, dec_hs) # Attentionの出すコンテキストベクトル\n",
    "        out = np.concatenate((c, dec_hs), axis=2) # LSTMの出力とコンテキストベクトルを連結して出力\n",
    "        score = self.affine.forward(out)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        N, T, H2 = dout.shape\n",
    "        H = H2 // 2 # 時系列の長さはcもdec_hsも同じなので単純に帰ってきた長さを半分にすればいい\n",
    "        \n",
    "        dc, ddec_hs1 = dout[:, :, :H], dout[:, :, H:] # 連結されていたので「Hまで」と「Hから」に分割\n",
    "        denc_hs, ddec_hs0 = self.attention.backward(dc)\n",
    "        ddec_hs = ddec_hs0 + ddec_hs1\n",
    "        dout = self.lstm.backward(ddec_hs) # dhは返さないのでメンバからとる\n",
    "        dh = self.lstm.dh\n",
    "        self.embed.backward(dout) # 入力方向へ重みを返す必要はない\n",
    "        \n",
    "        denc_hs[:, -1] += dh\n",
    "        return denc_hs\n",
    "    \n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        h = enc_hs[:, -1]\n",
    "        samples = []\n",
    "        sample_id = start_id # 時刻ごとに移り変わる\n",
    "        self.lstm.set_state(h)\n",
    "        \n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([sample_id]).reshape((1, 1)) # バッチ数1，時系列の長さ1の配列にする\n",
    "            \n",
    "            out = self.embed.forward(x)\n",
    "            dec_hs = self.lstm.forward(out)\n",
    "            c = self.attention.forward(enc_hs, dec_hs) \n",
    "            out = np.concatenate((c, dec_hs), axis=2) \n",
    "            score = self.affine.forward(out)\n",
    "            \n",
    "            # maxではなくargmaxを使うことでIDを取得できる\n",
    "            sampled = np.argmax(score.flatten()) # flattenで(V,)の形にする\n",
    "            samples.append(sampled)\n",
    "    \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seqの実装\n",
    "AttentionEncoderとAttentionDecoderを使うseq2seqを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionSeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        args = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = AttentionEncoder(*args) # 変更点\n",
    "        self.decoder = AttentionDecoder(*args) # 変更点\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "        \n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの評価\n",
    "翻訳問題に取り組んでみたいが，それは非常に大きなデータが必要で扱いにくいため，「日付フォーマット」問題を学習させる．  \n",
    "翻訳用のデータセットでは，英語とフランス語，英語とドイツ語の学習データがついになって用意されており，20GBもの大きさになる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日付フォーマットの変換問題\n",
    "<div style=\"text-align: center\">september 27, 1994 -> 1994-09-27</div>\n",
    "<div style=\"text-align: center\">JUN 17, 2013 -> 2013-01-17</div>\n",
    "\n",
    "のような問題に取り組む．  \n",
    "この問題は見た目よりは簡単ではなく，かつ入出力の結果が正しいかがわかりやすいため，Attentionがそれぞれの要素に正しく注意を払えているかを確認することができる．  \n",
    "<br>\n",
    "50,000個に登るデータがdataset/date.txtにあらかじめ用意してある．  \n",
    "sequence.pyからこのデータを簡単に扱える．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention付きseq2seqの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 4.08\n",
      "| epoch 1 |  iter 21 / 351 | time 7[s] | loss 3.09\n",
      "| epoch 1 |  iter 41 / 351 | time 13[s] | loss 1.90\n",
      "| epoch 1 |  iter 61 / 351 | time 20[s] | loss 1.72\n",
      "| epoch 1 |  iter 81 / 351 | time 27[s] | loss 1.46\n",
      "| epoch 1 |  iter 101 / 351 | time 34[s] | loss 1.19\n",
      "| epoch 1 |  iter 121 / 351 | time 41[s] | loss 1.14\n",
      "| epoch 1 |  iter 141 / 351 | time 47[s] | loss 1.09\n",
      "| epoch 1 |  iter 161 / 351 | time 54[s] | loss 1.06\n",
      "| epoch 1 |  iter 181 / 351 | time 61[s] | loss 1.04\n",
      "| epoch 1 |  iter 201 / 351 | time 68[s] | loss 1.03\n",
      "| epoch 1 |  iter 221 / 351 | time 75[s] | loss 1.02\n",
      "| epoch 1 |  iter 241 / 351 | time 82[s] | loss 1.02\n",
      "| epoch 1 |  iter 261 / 351 | time 89[s] | loss 1.01\n",
      "| epoch 1 |  iter 281 / 351 | time 95[s] | loss 1.00\n",
      "| epoch 1 |  iter 301 / 351 | time 102[s] | loss 1.00\n",
      "| epoch 1 |  iter 321 / 351 | time 109[s] | loss 1.00\n",
      "| epoch 1 |  iter 341 / 351 | time 116[s] | loss 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "X 1970-01-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 1970-01-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "X 1970-01-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 1970-01-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1970-01-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "X 1970-01-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "X 1970-01-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 1970-01-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1970-01-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 1970-01-11\n",
      "---\n",
      "val acc 0.000%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.00\n",
      "| epoch 2 |  iter 21 / 351 | time 7[s] | loss 1.00\n",
      "| epoch 2 |  iter 41 / 351 | time 14[s] | loss 0.99\n",
      "| epoch 2 |  iter 61 / 351 | time 21[s] | loss 0.99\n",
      "| epoch 2 |  iter 81 / 351 | time 29[s] | loss 0.99\n",
      "| epoch 2 |  iter 101 / 351 | time 36[s] | loss 0.99\n",
      "| epoch 2 |  iter 121 / 351 | time 44[s] | loss 0.99\n",
      "| epoch 2 |  iter 141 / 351 | time 51[s] | loss 0.98\n",
      "| epoch 2 |  iter 161 / 351 | time 58[s] | loss 0.98\n",
      "| epoch 2 |  iter 181 / 351 | time 66[s] | loss 0.97\n",
      "| epoch 2 |  iter 201 / 351 | time 72[s] | loss 0.95\n",
      "| epoch 2 |  iter 221 / 351 | time 80[s] | loss 0.94\n",
      "| epoch 2 |  iter 241 / 351 | time 87[s] | loss 0.90\n",
      "| epoch 2 |  iter 261 / 351 | time 94[s] | loss 0.83\n",
      "| epoch 2 |  iter 281 / 351 | time 101[s] | loss 0.74\n",
      "| epoch 2 |  iter 301 / 351 | time 108[s] | loss 0.66\n",
      "| epoch 2 |  iter 321 / 351 | time 116[s] | loss 0.58\n",
      "| epoch 2 |  iter 341 / 351 | time 123[s] | loss 0.46\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "X 1904-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 2006-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "X 2003-02-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 2916-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "X 1902-11-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "X 2006-01-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 2007-01-00\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1913-12-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 2916-11-08\n",
      "---\n",
      "val acc 10.040%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 0.35\n",
      "| epoch 3 |  iter 21 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 3 |  iter 41 / 351 | time 15[s] | loss 0.21\n",
      "| epoch 3 |  iter 61 / 351 | time 22[s] | loss 0.14\n",
      "| epoch 3 |  iter 81 / 351 | time 29[s] | loss 0.09\n",
      "| epoch 3 |  iter 101 / 351 | time 37[s] | loss 0.07\n",
      "| epoch 3 |  iter 121 / 351 | time 44[s] | loss 0.05\n",
      "| epoch 3 |  iter 141 / 351 | time 51[s] | loss 0.04\n",
      "| epoch 3 |  iter 161 / 351 | time 58[s] | loss 0.03\n",
      "| epoch 3 |  iter 181 / 351 | time 65[s] | loss 0.03\n",
      "| epoch 3 |  iter 201 / 351 | time 73[s] | loss 0.02\n",
      "| epoch 3 |  iter 221 / 351 | time 79[s] | loss 0.02\n",
      "| epoch 3 |  iter 241 / 351 | time 87[s] | loss 0.02\n",
      "| epoch 3 |  iter 261 / 351 | time 94[s] | loss 0.01\n",
      "| epoch 3 |  iter 281 / 351 | time 101[s] | loss 0.01\n",
      "| epoch 3 |  iter 301 / 351 | time 109[s] | loss 0.01\n",
      "| epoch 3 |  iter 321 / 351 | time 116[s] | loss 0.01\n",
      "| epoch 3 |  iter 341 / 351 | time 123[s] | loss 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 2006-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 2086-11-06\n",
      "---\n",
      "val acc 82.400%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 0.01\n",
      "| epoch 4 |  iter 21 / 351 | time 7[s] | loss 0.01\n",
      "| epoch 4 |  iter 41 / 351 | time 14[s] | loss 0.01\n",
      "| epoch 4 |  iter 61 / 351 | time 21[s] | loss 0.01\n",
      "| epoch 4 |  iter 81 / 351 | time 29[s] | loss 0.01\n",
      "| epoch 4 |  iter 101 / 351 | time 36[s] | loss 0.01\n",
      "| epoch 4 |  iter 121 / 351 | time 42[s] | loss 0.00\n",
      "| epoch 4 |  iter 141 / 351 | time 50[s] | loss 0.01\n",
      "| epoch 4 |  iter 161 / 351 | time 57[s] | loss 0.00\n",
      "| epoch 4 |  iter 181 / 351 | time 64[s] | loss 0.00\n",
      "| epoch 4 |  iter 201 / 351 | time 71[s] | loss 0.00\n",
      "| epoch 4 |  iter 221 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 4 |  iter 241 / 351 | time 86[s] | loss 0.00\n",
      "| epoch 4 |  iter 261 / 351 | time 94[s] | loss 0.00\n",
      "| epoch 4 |  iter 281 / 351 | time 101[s] | loss 0.00\n",
      "| epoch 4 |  iter 301 / 351 | time 109[s] | loss 0.00\n",
      "| epoch 4 |  iter 321 / 351 | time 116[s] | loss 0.00\n",
      "| epoch 4 |  iter 341 / 351 | time 124[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 2086-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 84.400%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 5 |  iter 21 / 351 | time 7[s] | loss 0.00\n",
      "| epoch 5 |  iter 41 / 351 | time 14[s] | loss 0.00\n",
      "| epoch 5 |  iter 61 / 351 | time 21[s] | loss 0.00\n",
      "| epoch 5 |  iter 81 / 351 | time 29[s] | loss 0.00\n",
      "| epoch 5 |  iter 101 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 5 |  iter 121 / 351 | time 43[s] | loss 0.00\n",
      "| epoch 5 |  iter 141 / 351 | time 50[s] | loss 0.00\n",
      "| epoch 5 |  iter 161 / 351 | time 58[s] | loss 0.00\n",
      "| epoch 5 |  iter 181 / 351 | time 65[s] | loss 0.00\n",
      "| epoch 5 |  iter 201 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 5 |  iter 221 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 5 |  iter 241 / 351 | time 86[s] | loss 0.00\n",
      "| epoch 5 |  iter 261 / 351 | time 93[s] | loss 0.00\n",
      "| epoch 5 |  iter 281 / 351 | time 101[s] | loss 0.00\n",
      "| epoch 5 |  iter 301 / 351 | time 108[s] | loss 0.00\n",
      "| epoch 5 |  iter 321 / 351 | time 115[s] | loss 0.00\n",
      "| epoch 5 |  iter 341 / 351 | time 122[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 2086-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 84.920%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 6 |  iter 21 / 351 | time 7[s] | loss 0.00\n",
      "| epoch 6 |  iter 41 / 351 | time 14[s] | loss 0.00\n",
      "| epoch 6 |  iter 61 / 351 | time 21[s] | loss 0.00\n",
      "| epoch 6 |  iter 81 / 351 | time 29[s] | loss 0.00\n",
      "| epoch 6 |  iter 101 / 351 | time 36[s] | loss 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 6 |  iter 121 / 351 | time 43[s] | loss 0.00\n",
      "| epoch 6 |  iter 141 / 351 | time 50[s] | loss 0.00\n",
      "| epoch 6 |  iter 161 / 351 | time 58[s] | loss 0.00\n",
      "| epoch 6 |  iter 181 / 351 | time 64[s] | loss 0.00\n",
      "| epoch 6 |  iter 201 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 6 |  iter 221 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 6 |  iter 241 / 351 | time 86[s] | loss 0.00\n",
      "| epoch 6 |  iter 261 / 351 | time 93[s] | loss 0.00\n",
      "| epoch 6 |  iter 281 / 351 | time 101[s] | loss 0.00\n",
      "| epoch 6 |  iter 301 / 351 | time 108[s] | loss 0.00\n",
      "| epoch 6 |  iter 321 / 351 | time 115[s] | loss 0.00\n",
      "| epoch 6 |  iter 341 / 351 | time 122[s] | loss 0.06\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1070-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "X 1992-12-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 57.860%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.01\n",
      "| epoch 7 |  iter 21 / 351 | time 7[s] | loss 0.01\n",
      "| epoch 7 |  iter 41 / 351 | time 14[s] | loss 0.00\n",
      "| epoch 7 |  iter 61 / 351 | time 21[s] | loss 0.00\n",
      "| epoch 7 |  iter 81 / 351 | time 29[s] | loss 0.00\n",
      "| epoch 7 |  iter 101 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 7 |  iter 121 / 351 | time 43[s] | loss 0.00\n",
      "| epoch 7 |  iter 141 / 351 | time 50[s] | loss 0.00\n",
      "| epoch 7 |  iter 161 / 351 | time 58[s] | loss 0.00\n",
      "| epoch 7 |  iter 181 / 351 | time 65[s] | loss 0.00\n",
      "| epoch 7 |  iter 201 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 7 |  iter 221 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 7 |  iter 241 / 351 | time 87[s] | loss 0.00\n",
      "| epoch 7 |  iter 261 / 351 | time 94[s] | loss 0.00\n",
      "| epoch 7 |  iter 281 / 351 | time 101[s] | loss 0.00\n",
      "| epoch 7 |  iter 301 / 351 | time 108[s] | loss 0.00\n",
      "| epoch 7 |  iter 321 / 351 | time 115[s] | loss 0.00\n",
      "| epoch 7 |  iter 341 / 351 | time 123[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1070-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 82.760%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 8 |  iter 21 / 351 | time 7[s] | loss 0.00\n",
      "| epoch 8 |  iter 41 / 351 | time 14[s] | loss 0.00\n",
      "| epoch 8 |  iter 61 / 351 | time 22[s] | loss 0.00\n",
      "| epoch 8 |  iter 81 / 351 | time 29[s] | loss 0.00\n",
      "| epoch 8 |  iter 101 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 8 |  iter 121 / 351 | time 43[s] | loss 0.00\n",
      "| epoch 8 |  iter 141 / 351 | time 50[s] | loss 0.00\n",
      "| epoch 8 |  iter 161 / 351 | time 58[s] | loss 0.00\n",
      "| epoch 8 |  iter 181 / 351 | time 64[s] | loss 0.00\n",
      "| epoch 8 |  iter 201 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 8 |  iter 221 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 8 |  iter 241 / 351 | time 87[s] | loss 0.00\n",
      "| epoch 8 |  iter 261 / 351 | time 93[s] | loss 0.00\n",
      "| epoch 8 |  iter 281 / 351 | time 100[s] | loss 0.00\n",
      "| epoch 8 |  iter 301 / 351 | time 108[s] | loss 0.00\n",
      "| epoch 8 |  iter 321 / 351 | time 115[s] | loss 0.00\n",
      "| epoch 8 |  iter 341 / 351 | time 123[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1070-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 83.780%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 9 |  iter 21 / 351 | time 7[s] | loss 0.00\n",
      "| epoch 9 |  iter 41 / 351 | time 14[s] | loss 0.00\n",
      "| epoch 9 |  iter 61 / 351 | time 21[s] | loss 0.00\n",
      "| epoch 9 |  iter 81 / 351 | time 29[s] | loss 0.00\n",
      "| epoch 9 |  iter 101 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 9 |  iter 121 / 351 | time 44[s] | loss 0.00\n",
      "| epoch 9 |  iter 141 / 351 | time 52[s] | loss 0.00\n",
      "| epoch 9 |  iter 161 / 351 | time 61[s] | loss 0.00\n",
      "| epoch 9 |  iter 181 / 351 | time 68[s] | loss 0.00\n",
      "| epoch 9 |  iter 201 / 351 | time 77[s] | loss 0.00\n",
      "| epoch 9 |  iter 221 / 351 | time 85[s] | loss 0.00\n",
      "| epoch 9 |  iter 241 / 351 | time 92[s] | loss 0.00\n",
      "| epoch 9 |  iter 261 / 351 | time 100[s] | loss 0.00\n",
      "| epoch 9 |  iter 281 / 351 | time 107[s] | loss 0.00\n",
      "| epoch 9 |  iter 301 / 351 | time 115[s] | loss 0.00\n",
      "| epoch 9 |  iter 321 / 351 | time 122[s] | loss 0.00\n",
      "| epoch 9 |  iter 341 / 351 | time 130[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 85.380%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 10 |  iter 21 / 351 | time 7[s] | loss 0.00\n",
      "| epoch 10 |  iter 41 / 351 | time 14[s] | loss 0.00\n",
      "| epoch 10 |  iter 61 / 351 | time 22[s] | loss 0.00\n",
      "| epoch 10 |  iter 81 / 351 | time 29[s] | loss 0.00\n",
      "| epoch 10 |  iter 101 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 10 |  iter 121 / 351 | time 43[s] | loss 0.00\n",
      "| epoch 10 |  iter 141 / 351 | time 50[s] | loss 0.00\n",
      "| epoch 10 |  iter 161 / 351 | time 58[s] | loss 0.00\n",
      "| epoch 10 |  iter 181 / 351 | time 65[s] | loss 0.00\n",
      "| epoch 10 |  iter 201 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 10 |  iter 221 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 10 |  iter 241 / 351 | time 86[s] | loss 0.00\n",
      "| epoch 10 |  iter 261 / 351 | time 94[s] | loss 0.00\n",
      "| epoch 10 |  iter 281 / 351 | time 100[s] | loss 0.00\n",
      "| epoch 10 |  iter 301 / 351 | time 108[s] | loss 0.00\n",
      "| epoch 10 |  iter 321 / 351 | time 115[s] | loss 0.00\n",
      "| epoch 10 |  iter 341 / 351 | time 122[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 2913-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 86.440%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x185c2893780>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 入力文を反転\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse=True)\n",
    "    \n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "model.save_params()\n",
    "plt.plot(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1エポック目から急速に正解率を高め，3エポック目ではすでにほとんどの問題に正解できる．  \n",
    "単純なseq2seqでは10エポックを経過してもほとんど不正解になってしまう．  \n",
    "Peekyなseq2seqでは4エポック目で正解を出す．  \n",
    "しかし，時系列データが長くなるに連れて学習の速さだけでなく，精度の点においてもAttentionはPeekySeq2seqより有利になるであろう．  \n",
    "<br>\n",
    "ACC1.0はなかなかいかない…何か間違ってる？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentionの可視化\n",
    "Attentionが時系列変換を行うときにどの要素に注意を払っているのかを可視化する．  \n",
    "Attentionの重みは，どの文字が別のどの文字に対応しているかを確率分布で示すことができる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Visualization](AUGUSTto08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可視化してみると，seq2seqが\n",
    "- 「AUGUST」が「08」に対応\n",
    "- 「1983」が「最初に来る1983」に対応\n",
    "\n",
    "していることを学習できていることがわかる．  \n",
    "このことから，seq2seqは我々人間と同じように，必要な情報に注意を向けることができたといえる．  \n",
    "一般的にニューラルネットワークの内部の処理は理解できないが，Attentionは人間が理解可能な構造や意味をモデルに与えることができる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionに関する残りのテーマ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 双方向RNN\n",
    "LSTMの各時刻の隠れベクトルは$hs$にまとめられ，$hs$の各行には対応する単語の成分が多く含まれる．  \n",
    "このとき，各行の成分には過去の単語の情報も含まれるが，未来の情報もバランスよく含ませたい場合は，**双方向LSTM**(**双方向RNN**)を使う．  \n",
    "<br>\n",
    "双方向LSTMのモデルは，順方向の出力に加え，逆方向に時系列データを学習させるTimeLSTMレイヤを追加し，順方向のTimeLSTMレイヤと時刻ごとに連結を行い，$hs$としてまとめて最終的な隠れ状態ベクトルとする．  \n",
    "なお，連結以外にも「和」や「平均」などを使うこともある．  \n",
    "実装はcommon/time_layers.pyのTimeBiLSTMクラスにある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentionレイヤの使用方法\n",
    "Attentionレイヤを利用する場所は，TimeAffineレイヤとTimeLSTMレイヤの間とは限らない．  \n",
    "例えば，TimeLSTMの各時刻間にAttentionを挿入することもある.  \n",
    "どのような構成にすれば精度がよくなるかは，実際のデータをみてみないとわからない．  \n",
    "どちらかというと我々が実装した方が実装はしやすい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seqの深層化とskipコネクション\n",
    "翻訳などの現実的なアプリケーションでは，問題が複雑になる．  \n",
    "その場合，Attention付きseq2seqのRNNレイヤを深く重ねることで表現力を高める．  \n",
    "<br>\n",
    "一例としてAttentionはDecoderの最初のLSTMと他のLSTMの間に挟んでいるが，複数のAttentionレイヤを使ったり，Attentionの出力を次の時刻のLSTMレイヤへ入力したりと，様々なバリエーションが考えられる．  \n",
    "しかし，レイヤを深くすると過学習の危険があるので，その場合Dropoutや重み共有などの技術が必要．  \n",
    "<br>\n",
    "層を深くするとき，**skipコネクション**というテクニックを使っても過学習を起こしにくくできる.  \n",
    "これは，層をまたいで先の層の出力に加算するテクニックである．  \n",
    "逆伝播の時も，足し算の逆伝播はそのまま流して分岐元で加算するだけなので簡単．  \n",
    "<br>\n",
    "skipコネクションは，RNNの深さ方向への勾配消失を防ぐのにも有効である，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの応用\n",
    "Attentionというアイデア自体は汎用的であり，さらに多くの可能性を秘めている．  \n",
    "Attentionを使った最先端の研究例を3つ紹介．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Neural Machine Translation (GNMT)\n",
    "機械翻訳の歴史\n",
    "- ルールベース翻訳\n",
    "- 用例ベース翻訳\n",
    "- 統計ベース翻訳\n",
    "- ニューラル翻訳 (Neural Machine Translation) ←\n",
    "\n",
    "ニューラル翻訳はこれまでの統計翻訳と対比する形で用いられてきたが，最近ではseq2seqを使った機械翻訳の総称として用いられている．  \n",
    "Google翻訳は2016年からニューラル翻訳が使われており，このシステムはGNMTと呼ばれている．  \n",
    "GNMTもAttention付きEncoder-Decoderモデルによるseq2seqがベースになっている．  \n",
    "それに加え，  \n",
    "- LSTMレイヤの多層化\n",
    "- Encoderの一層目を双方向LSTM化\n",
    "- skipコネクション\n",
    "- 複数GPUでの分散学習\n",
    "- 程頻出単語の対応\n",
    "- 推論時の高速化のための量子化\n",
    "\n",
    "などのテクニックがふんだんに利用されている．  \n",
    "GNMTは，英語とフランス語やスペイン語の相互翻訳(中国語は人間でも難しい)ではほぼ人間の制度に近づいており，統計ベース機会翻訳の一つである「フレーズベースの機械翻訳」よりも高い制度を実現することができた．  \n",
    "<br>\n",
    "しかし，まだまだ不自然な翻訳や，人間ならば発生しないミスも散見される．  \n",
    "そのため，これから先も機械翻訳の研究は進められていく．  \n",
    "現在でもニューラル翻訳を中心に活発に研究が行われている．  \n",
    "<br>\n",
    "GNMTには100枚近くのGPUを使って6日間の学習を行ったり，8つのモデルを並行して学習するアンサンブル学習を行っていたり，強化学習によってさらなる制度向上を成し遂げる工夫もなされている．  \n",
    "そのようなことは我々1個人には難しいが，そのコアとなる知識を我々はすでに習得した．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "RNNの欠点として，前時刻に計算した結果を用いて逐次的に計算を行うため，並列計算ができないことが挙げられる．  \n",
    "そのため，現在ではRNNを取り除く，もしくは並列計算可能なRNNの研究が活発に行われている．  \n",
    "<br>\n",
    "有名なものに，Transformerモデルと呼ばれるものがあり，「Attention is all you need」という論文で提案された手法である．  \n",
    "<br>\n",
    "TransformerモデルはSelf-Attentionというテクニックが使用される点が重要．  \n",
    "Self-Attentionは，一つの時系列データ内において，各要素が他の要素に対してどのような関連性があるのかを見ていこうというものである．  \n",
    "通常のAttentionはEncoderからの$hs\\_enc$とDecoderのLSTMの出力$hs\\_dec$を入力として受け取る．  \n",
    "一方Self-Attentionは，一つの時系列データ$hs$をコピーし，それぞれに入力する．  \n",
    "<br>\n",
    "Transformerモデルでは，TimeLSTM層の代わりにSelf-Attentionが使われる．  \n",
    "EncoderではFeedFowardレイヤと呼ばれるものを使用する．  \n",
    "FeedFowardレイヤは，隠れ層が1層で，活性化関数にReLUを用いた全結合のNNである．  \n",
    "そのようにして作られたEncoder,DecoderをN回，問題によって積み重ね，seq2seqを実現する．\n",
    "<br>\n",
    "実際のTransformerモデルでは，そうして作られたモデルに，さらにskipコネクションやLayer Normalization，複数のAttention，Positional Encoding(時系列データの位置情報をエンコード)といった工夫がなされている．\n",
    "<br>\n",
    "このようにして計算量を抑え，GPUによる並列計算の恩恵を受けることで学習時間を大幅に減らすことに成功した．  \n",
    "さらに翻訳制度もGNMTや，CNNを使った翻訳のBLEWスコアという指標で上回った．  \n",
    "<br>\n",
    "このように，AttentionはRNNを置き換えるモジュールとして利用することもできる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer以外にも，RNNをConvolutionレイヤに置き換えてseq2seqを構成し，並列化計算を可能にする研究もある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Turing Machine(NTM)\n",
    "人間が紙とペンを使うように，NNにも外部メモリを利用させることで，さらなる力を付加することができる．  \n",
    "RNNやLSTMの内部状態，隠れベクトルは固定長であり，詰めこめる情報量には制限があるため，外部記憶に記録するというアプローチが考えられる．  \n",
    "<br>\n",
    "Attention付きseq2seqではEncoderは入力文をエンコードし，Decoderがエンコードされた情報を利用していた．  \n",
    "ここでAttentionはEncoderによって情報を書き込まれ，Decoderによって読み込みを行われていたと考えられる．  \n",
    "このように，Attentionを使ってコンピュータのメモリ操作をNNによって再現できそうである．  \n",
    "<br>\n",
    "そのような研究の中で有名なものとして，**NTM**(Neural Turing Machine)がある．  \n",
    "NTMはDeepMindのチームによって行われた研究で，後に**DNC**(Differentiable Neural Computers)と呼ばれる手法に改良されている．\n",
    "<br>\n",
    "NTMは，コントローラと呼ばれる処理装置(RNNを利用したNN)にメモリを扱えるようにしたものである．  \n",
    "メモリを扱うのに，必要な情報を書き，不要な情報を消去し，必要な情報を読み込むといった動作が任意の場所で行える．  \n",
    "NTMは，そのようなメモリ操作を「微分可能」な計算で実現しており，データから手順を学ぶことができる．  \n",
    "つまり，アルゴリズムの入力と出力から，アルゴリズムやロジック自体を学ぶことができる．\n",
    "<br>\n",
    "NTMのレイヤ構成は，大まかにはEncoderのLSTMが「Write head」によってMemoryにデータを書き込み，Decoderはそのメモリから重要なデータを読み込む．  \n",
    "メモリに対して，ある番地にあるデータを読み書きするときには，「選択」する操作なので，Attentionの時と同じように重みによって選択を行う．  \n",
    "<br>\n",
    "NTMが行うメモリ操作には，2つのAttentionを用いる．  \n",
    "- コンテンツベースのAttention\n",
    "    - 従来の，クエリベクトルに似たベクトルをメモリから見つけるAttention\n",
    "- 位置ベースのAttention\n",
    "    - 前時刻に注目したメモリの位置に対して，その前後に移動するAttention\n",
    "    - メモリを一つずつ進めながら読んでいくコンピュータ特有の動きを再現しやすくなる\n",
    "\n",
    "NTMでは他にも，Attentionの重みをシャープにする処理や，前時刻のAttentionの重みを足し合わせる処理などがある．  \n",
    "<br>\n",
    "NTMは外部メモリを自由に利用することで，長い時系列を記憶する問題や，ソートの問題を解くことに成功した．  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
