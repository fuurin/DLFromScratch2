{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語の分散表現を得るため，前章ではカウントベースの手法を実装したのに対し，本章では推論ベースの手法であるWord2Vecを実装する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "word2vecのCBOWモデルと呼ばれるNNについて詳しく説明し，実装を行なった．  \n",
    "- 推論ベースの手法\n",
    "    - コンテキスト，ターゲット間の関係を推論する問題を通して，その副産物として単語の分散表現（ベクトル表現）を得る\n",
    "    - 単語が追加された時，1から計算をやり直さなくてはならないカウントベースの手法と比べ，それまでの重みを初期値として利用できる点で効率的．\n",
    "    - word2vec\n",
    "        - 基本的には2層のNN\n",
    "        - MatMulレイヤとSoftmaxWithLossレイヤによる分類問題として構成されるモデル\n",
    "        - 小さなコーパスでも学習はできる．\n",
    "        - 現状では処理効率がよくない．  \n",
    "        - CBOWモデル\n",
    "            - コンテキストからターゲットを推論する問題\n",
    "        - skip-gram モデル\n",
    "            - ターゲットからコンテキストを推論する問題\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論ベースの手法とニューラルネットワーク\n",
    "カウントベースの手法も推論ベースの手法も分布仮説に基づいている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウントベースの手法の問題点\n",
    "カウントベースの手法は大規模なコーパスでは扱いが難しい．  \n",
    "100万単語を扱うなら，100万×100万の行列を作り，それに対して$O(n^3)$のSVDを行う必要があり，現実的でない．  \n",
    "一方で，推論ベースの手法はミニバッチによる逐次的な学習が可能であり，GPUによる並列計算も可能である．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論ベースの手法の概要\n",
    "推論ベースの手法では，「you ? goodbye and I say hello」の?にあたる単語を推測する問題を解き，学習する．  \n",
    "you,goodbyeというコンテキストをモデルに渡して学習させると，? の部分に入る単語の確率分布を得る，といった形になる．  \n",
    "その結果が単語の分散表現になる．  \n",
    "そして今回，そのモデルには，ニューラルネットワークを用いる．  \n",
    "カウントベースの手法も，推論ベースの手法も，「単語の共起性」をいかにモデル化するかが重要な研究テーマになっている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークにおける単語の処理方法\n",
    "NNでは単語をone-hotベクトルに変換して取り扱う．  \n",
    "one-hotベクトルは，語彙数を$n$とすると，$n$次元ベクトルで表され，値が1である1つの要素を除き全てが0のベクトルである．  \n",
    "こうすることで，NNの入力層はニューロンの数を$n$に固定できる．  \n",
    "なお，本章で使用する全結合層では，バイアスを省略する．(MatMulレイヤに相当)  \n",
    "\n",
    "例えば，入力が7次元，中間層が3次元なら，重み行列は7×3になり，以下のようなコードになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07880115  0.63280227 -1.99906065]]\n",
      "[[-0.07880115  0.63280227 -1.99906065]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[1,0,0,0,0,0,0]]) # ミニバッチ処理を考慮して2次元になっている．\n",
    "W = np.random.randn(7, 3)\n",
    "h = c @ W\n",
    "print(h)\n",
    "\n",
    "# Matmulレイヤによる計算\n",
    "from common.layers import MatMul\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cはone-hotベクトルであるため，Wの1行目を抜き出してhとしていることとなる．  \n",
    "この非効率性の改良は次章で行う．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルなword2vec\n",
    "コンテキストから単語の分散表現を得るために用いるモデルの部分に，NNを組み込みたい．  \n",
    "そのNNとして，continuous bag-of-words (CBOW)というものを用いる方法を説明する．  \n",
    "\n",
    "word2vecは本来プログラムやツール類のことを指すが，今の文脈ではNNのモデルを指す．  \n",
    "正しくは，このCBOWモデルと，skip-gramモデル(3.5.3)のいずれかを指す模様．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOWモデルの推論処理\n",
    "コンテキスト(周囲の単語)からターゲット(中央の単語)を推測することを目的としたNN．  \n",
    "CBOWモデルへの入力はコンテキスト  \n",
    "\n",
    "コンテキストとなる単語が2つあるなら，入力層は2つになり，中間層と出力層によってCBOWモデルはなる．  \n",
    "入力層から中間層への重みをWin, 中間層から出力層への重みをWoutと呼ぶ．  \n",
    "\n",
    "中間層の出力は各入力層の全結合による変換後の値が平均されたものになる．  \n",
    "1つ目の入力層がh1，2つ目の入力層がh2に変換されたとすると，中間層のニューロンは$\\frac{1}{2} (h_1 + h_2)$となる．  \n",
    "\n",
    "出力層では各単語のスコアを算出し，Softmax関数を適用することでその単語がターゲットに当てはまる確率を求められる．  \n",
    "ここでは，Softmaxに通す前のノードを出力層と呼ぶことにする．  \n",
    "\n",
    "Winの部分の重みが単語の分散表現になり，Winでは「単語の意味」もうまくエンコードされている．  \n",
    "\n",
    "ここでポイントとなるのは，中間層のニューロンの数を入力層のものよりも減らすことにある．  \n",
    "中間層では，単語を予測するために必要な情報をコンパクトに収め，密なベクトル表現を得る．  \n",
    "\n",
    "中間層の情報は我々には理解できない「コード」で書かれている．  \n",
    "学習して，中間層の情報にすることをエンコード，逆にその情報から目的の結果を得ることをデコードという．  \n",
    "\n",
    "計算グラフでCBOWモデルを表すと，\n",
    "- 2つの入力ベクトルをWinを持つMatMulレイヤに通す．\n",
    "- その2つの入力を加算レイヤに渡し，和を得る．\n",
    "- それに0.5をかける乗算レイヤを通す．\n",
    "- それをWoutを持つMatMulレイヤに通す．\n",
    "- scoreを得る．\n",
    "\n",
    "CBOWモデルの推論処理をPythonで実装してみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12576574 -0.25113191  0.14258779 -0.11432049 -0.01785427  0.46932842\n",
      "  -0.11032777]]\n"
     ]
    }
   ],
   "source": [
    "from common.layers import MatMul\n",
    "\n",
    "c0 = ([[1,0,0,0,0,0,0]])\n",
    "c1 = ([[0,0,1,0,0,0,0]])\n",
    "\n",
    "W_in = np.random.randn(7,3)\n",
    "W_out = np.random.randn(3,7)\n",
    "\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOWモデルの学習\n",
    "CBOWモデルやskip-gramモデルによって得られる単語の分散表現は，特にWikipediaなどの大規模コーパスを使うと，意味的にも文法的にも我々の直感と合致するケースが多い．  \n",
    "\n",
    "CBOWモデルは，単語の出現パターンを学ぶだけなので，コーパスが違えば学習で得られる単語の分散表現も異なる．  \n",
    "例えば，スポーツの記事だけを扱う場合と，音楽の記事だけを扱う場合には，得られる単語の分散表現は異なる．  \n",
    "\n",
    "学習は単純に多クラス分類を行うNNを構築すればよい．  \n",
    "出力をSoftmax関数に渡し，教師ラベルとの交差エントロピー誤差を求め，それを損失として逆伝播し，学習させる．  \n",
    "このとき，SoftMaxWithLossレイヤを用いればよい．  \n",
    "\n",
    "単語の分散表現としては，Winのみを使うのがポピュラーなやり方．  \n",
    "\n",
    "文献38: Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modelingでは，Winのみを使うことの有効性が示されている．  \n",
    "文献27: Glove: Global Vectors for Word Representation で示されているword2vecに似た手法では，WinとWoutの和が有効であると報告されている．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの準備\n",
    "You say goodbye and I say hello という1文をコーパスとして用いる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンテキストとターゲット\n",
    "我々が行うべきことは，コンテキストとなる単語集合をNNに入力した時に，ターゲットの単語が出現する確率を高めること．  \n",
    "コーパスから，両端を除いた単語をターゲット，それらの左右の1単語2つをコンテキストとして抜き出し，学習データとする．  \n",
    "\n",
    "これから，コーパスからコンテキストとターゲットを作成する関数を実装する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは2章で実装したpreprocess関数を使って，文章から単語IDによるコーパスと単語ID間辞書を生成する．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，コーパスからコンテキストとターゲットを作成する関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size+1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "    \n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "print(contexts)\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot表現への変換\n",
    "コンテキストとターゲットをone-hot表現に変換する．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n",
      "\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n"
     ]
    }
   ],
   "source": [
    "from common.util import convert_one_hot\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "context = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "print(target)\n",
    "print()\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOWモデルの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        # 重みの初期化\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        layers = [\n",
    "            self.in_layer0,\n",
    "            self.in_layer1,\n",
    "            self.out_layer\n",
    "        ]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # メンバ変数に単語の分散表現を設定\n",
    "        self.word_vecs = W_in\n",
    "    \n",
    "    # contexts: 3次元のNumPy配列，ミニバッチ：コンテキスト：one-hotベクトル\n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは，同じ重みW_inを複数のレイヤ，0,1で共有している．  \n",
    "そのため，同じ重みがparams配列に存在してしまい，AdamやOptimizerの処理が本来の挙動と異なってしまう．  \n",
    "そこで，Trainerクラスの内部では，パラメータの更新時にパラメータの重複を取り除くremove_duplicate関数が利用されている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの実装\n",
    "通常のNNの学習と全く同じ．  \n",
    "- 学習データを準備\n",
    "- 学習データをNNに与える\n",
    "- 勾配降下法と誤差逆伝播による重みパラメータのアップデートを繰り返す\n",
    "- アップデートしながら精度を確認していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 2 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 3 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 4 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 5 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 6 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 7 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 8 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 9 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 10 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 11 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 12 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 13 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 14 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 15 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 16 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 17 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 18 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 19 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 20 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 21 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 22 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 23 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 24 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 25 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 26 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 27 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 28 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 29 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 30 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 31 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 32 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 33 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 34 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 35 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 36 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 37 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 38 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 39 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 40 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 41 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 42 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 43 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 44 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 45 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 46 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 47 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 48 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 49 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 50 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 51 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 52 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 53 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 54 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 55 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 56 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 57 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 58 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
      "| epoch 59 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 60 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 61 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 62 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 63 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
      "| epoch 64 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 65 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
      "| epoch 66 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
      "| epoch 67 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 68 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
      "| epoch 69 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
      "| epoch 70 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
      "| epoch 71 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
      "| epoch 72 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 73 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 74 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 75 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 76 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 77 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 78 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
      "| epoch 79 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
      "| epoch 80 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 81 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
      "| epoch 82 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 83 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 84 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 85 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 86 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
      "| epoch 87 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 88 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
      "| epoch 89 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 90 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
      "| epoch 91 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
      "| epoch 92 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 93 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
      "| epoch 94 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
      "| epoch 95 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
      "| epoch 96 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
      "| epoch 97 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
      "| epoch 98 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 99 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
      "| epoch 100 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
      "| epoch 101 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 102 |  iter 1 / 2 | time 0[s] | loss 1.70\n",
      "| epoch 103 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
      "| epoch 104 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 105 |  iter 1 / 2 | time 0[s] | loss 1.70\n",
      "| epoch 106 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 107 |  iter 1 / 2 | time 0[s] | loss 1.67\n",
      "| epoch 108 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
      "| epoch 109 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
      "| epoch 110 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
      "| epoch 111 |  iter 1 / 2 | time 0[s] | loss 1.69\n",
      "| epoch 112 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
      "| epoch 113 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
      "| epoch 114 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
      "| epoch 115 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 116 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 117 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
      "| epoch 118 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
      "| epoch 119 |  iter 1 / 2 | time 0[s] | loss 1.69\n",
      "| epoch 120 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
      "| epoch 121 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
      "| epoch 122 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 123 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
      "| epoch 124 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
      "| epoch 125 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
      "| epoch 126 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
      "| epoch 127 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
      "| epoch 128 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
      "| epoch 129 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
      "| epoch 130 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 131 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 132 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
      "| epoch 133 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
      "| epoch 134 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 135 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 136 |  iter 1 / 2 | time 0[s] | loss 1.48\n",
      "| epoch 137 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
      "| epoch 138 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 139 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
      "| epoch 140 |  iter 1 / 2 | time 0[s] | loss 1.49\n",
      "| epoch 141 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 142 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
      "| epoch 143 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 144 |  iter 1 / 2 | time 0[s] | loss 1.49\n",
      "| epoch 145 |  iter 1 / 2 | time 0[s] | loss 1.49\n",
      "| epoch 146 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 147 |  iter 1 / 2 | time 0[s] | loss 1.44\n",
      "| epoch 148 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
      "| epoch 149 |  iter 1 / 2 | time 0[s] | loss 1.44\n",
      "| epoch 150 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
      "| epoch 151 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
      "| epoch 152 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
      "| epoch 153 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
      "| epoch 154 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 155 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 156 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
      "| epoch 157 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
      "| epoch 158 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
      "| epoch 159 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
      "| epoch 160 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
      "| epoch 161 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 162 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
      "| epoch 163 |  iter 1 / 2 | time 0[s] | loss 1.37\n",
      "| epoch 164 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
      "| epoch 165 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
      "| epoch 166 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 167 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
      "| epoch 168 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 169 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 170 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 171 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
      "| epoch 172 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
      "| epoch 173 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 174 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 175 |  iter 1 / 2 | time 0[s] | loss 1.48\n",
      "| epoch 176 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 177 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 178 |  iter 1 / 2 | time 0[s] | loss 1.37\n",
      "| epoch 179 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
      "| epoch 180 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 181 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 182 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 183 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 184 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 185 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
      "| epoch 186 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 187 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 188 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 189 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 190 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 191 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 192 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
      "| epoch 193 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 194 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 195 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
      "| epoch 196 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
      "| epoch 197 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
      "| epoch 198 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 199 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 200 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
      "| epoch 201 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 202 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
      "| epoch 203 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 204 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 205 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 206 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 207 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 208 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 209 |  iter 1 / 2 | time 0[s] | loss 1.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 210 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 211 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
      "| epoch 212 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 213 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 214 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 215 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
      "| epoch 216 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 217 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
      "| epoch 218 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 219 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 220 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 221 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
      "| epoch 222 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 223 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 224 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 225 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 226 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 227 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 228 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
      "| epoch 229 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 230 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
      "| epoch 231 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 232 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 233 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 234 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 235 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 236 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 237 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 238 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 239 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 240 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 241 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 242 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 243 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 244 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 245 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 246 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 247 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
      "| epoch 248 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 249 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 250 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 251 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 252 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 253 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 254 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 255 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 256 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 257 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 258 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 259 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 260 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 261 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 262 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 263 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 264 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 265 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 266 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 267 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 268 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 269 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
      "| epoch 270 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 271 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 272 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 273 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
      "| epoch 274 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 275 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 276 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
      "| epoch 277 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 278 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
      "| epoch 279 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 280 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 281 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 282 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 283 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 284 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 285 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 286 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 287 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 288 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 289 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 290 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 291 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 292 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 293 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 294 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 295 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 296 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 297 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 298 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 299 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 300 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 301 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 302 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 303 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 304 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 305 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 306 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 307 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 308 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 309 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 310 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 311 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
      "| epoch 312 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 313 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 314 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 315 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 316 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 317 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 318 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 319 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 320 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 321 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 322 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 323 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 324 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 325 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 326 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 327 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 328 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
      "| epoch 329 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 330 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 331 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 332 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 333 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 334 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 335 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 336 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 337 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 338 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 339 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 340 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 341 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 342 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
      "| epoch 343 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 344 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 345 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 346 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 347 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 348 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 349 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 350 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 351 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 352 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 353 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 354 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 355 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 356 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 357 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 358 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 359 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 360 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 361 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 362 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 363 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 364 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 365 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 366 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 367 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 368 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 369 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 370 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 371 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 372 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 373 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
      "| epoch 374 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 375 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 376 |  iter 1 / 2 | time 0[s] | loss 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 377 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 378 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 379 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 380 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 381 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 382 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 383 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 384 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 385 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 386 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 387 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 388 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 389 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 390 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 391 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 392 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 393 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 394 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 395 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 396 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 397 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 398 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 399 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 400 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
      "| epoch 401 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 402 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 403 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 404 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 405 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 406 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 407 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 408 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 409 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 410 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 411 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 412 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 413 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 414 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 415 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 416 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 417 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 418 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 419 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 420 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 421 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 422 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 423 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 424 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 425 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 426 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 427 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 428 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 429 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 430 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 431 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 432 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 433 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 434 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 435 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 436 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 437 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 438 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 439 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 440 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 441 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 442 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 443 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 444 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 445 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 446 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 447 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 448 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 449 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 450 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 451 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 452 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 453 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 454 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 455 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 456 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 457 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 458 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 459 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 460 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 461 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 462 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 463 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 464 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 465 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 466 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 467 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 468 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 469 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 470 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 471 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 472 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 473 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 474 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 475 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 476 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 477 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 478 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 479 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 480 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 481 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 482 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 483 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 484 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 485 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 486 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 487 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 488 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 489 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 490 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 491 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 492 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 493 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 494 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 495 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 496 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 497 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 498 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 499 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 500 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 501 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 502 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 503 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 504 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
      "| epoch 505 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 506 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 507 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 508 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 509 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 510 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 511 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 512 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 513 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 514 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 515 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 516 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 517 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 518 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 519 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 520 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 521 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 522 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 523 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 524 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 525 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 526 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 527 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 528 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 529 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 530 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 531 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 532 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 533 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 534 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 535 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 536 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 537 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 538 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 539 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 540 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 541 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 542 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 543 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 544 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 545 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 546 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 547 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 548 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 549 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 550 |  iter 1 / 2 | time 0[s] | loss 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 551 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 552 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 553 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 554 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 555 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 556 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 557 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 558 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 559 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 560 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 561 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 562 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 563 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 564 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 565 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 566 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 567 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 568 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 569 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 570 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 571 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 572 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 573 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 574 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 575 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 576 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 577 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 578 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 579 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 580 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 581 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 582 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 583 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 584 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 585 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 586 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 587 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 588 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 589 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 590 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 591 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 592 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 593 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 594 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 595 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 596 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 597 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 598 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 599 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 600 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 601 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 602 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 603 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 604 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 605 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 606 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 607 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 608 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 609 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 610 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 611 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 612 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 613 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 614 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 615 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 616 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 617 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 618 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 619 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 620 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 621 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 622 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 623 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 624 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
      "| epoch 625 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 626 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 627 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 628 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 629 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 630 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 631 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 632 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 633 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 634 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 635 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 636 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 637 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 638 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 639 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 640 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 641 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 642 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 643 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 644 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 645 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 646 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 647 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 648 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 649 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 650 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 651 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 652 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 653 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 654 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 655 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 656 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 657 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 658 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 659 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 660 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 661 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 662 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 663 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 664 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 665 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 666 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 667 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 668 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 669 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 670 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 671 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 672 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 673 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 674 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 675 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 676 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 677 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 678 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 679 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 680 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 681 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 682 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 683 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 684 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 685 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 686 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 687 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 688 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 689 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 690 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 691 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 692 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 693 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 694 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 695 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 696 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 697 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 698 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 699 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 700 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 701 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 702 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 703 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 704 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 705 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 706 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 707 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 708 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 709 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 710 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 711 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 712 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 713 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 714 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 715 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 716 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 717 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 718 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
      "| epoch 719 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 720 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 721 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 722 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 723 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 724 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 725 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 726 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 727 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 728 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 729 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 730 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 731 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 732 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 733 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 734 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 735 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 736 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 737 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 738 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 739 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 740 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 741 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 742 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 743 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 744 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 745 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 746 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 747 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 748 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 749 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 750 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 751 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 752 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 753 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 754 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 755 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 756 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 757 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 758 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 759 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 760 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 761 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 762 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 763 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 764 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 765 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 766 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 767 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 768 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 769 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 770 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 771 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 772 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 773 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 774 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 775 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 776 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 777 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 778 |  iter 1 / 2 | time 0[s] | loss 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 779 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 780 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 781 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 782 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 783 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 784 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 785 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 786 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 787 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 788 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 789 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 790 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 791 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 792 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 793 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 794 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 795 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 796 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 797 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 798 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 799 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 800 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 801 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 802 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 803 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 804 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 805 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 806 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 807 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 808 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 809 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 810 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 811 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 812 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 813 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 814 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 815 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 816 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 817 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 818 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 819 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 820 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 821 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 822 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 823 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 824 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 825 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 826 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 827 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 828 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 829 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 830 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 831 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 832 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 833 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 834 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 835 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 836 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 837 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 838 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 839 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 840 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 841 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 842 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 843 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 844 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 845 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 846 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 847 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 848 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 849 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 850 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 851 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 852 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 853 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 854 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 855 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 856 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 857 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 858 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 859 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 860 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 861 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 862 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 863 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 864 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 865 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 866 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 867 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 868 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 869 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 870 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 871 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 872 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 873 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 874 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 875 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 876 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 877 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 878 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 879 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 880 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 881 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 882 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 883 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 884 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 885 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 886 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 887 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 888 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 889 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 890 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 891 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 892 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 893 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 894 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 895 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 896 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 897 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 898 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 899 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 900 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 901 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 902 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 903 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 904 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 905 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 906 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 907 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 908 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 909 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 910 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 911 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 912 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 913 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 914 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 915 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 916 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 917 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 918 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 919 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 920 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 921 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 922 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 923 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 924 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 925 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 926 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 927 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 928 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 929 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 930 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 931 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 932 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 933 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 934 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 935 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 936 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 937 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 938 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 939 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 940 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 941 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 942 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 943 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 944 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 945 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 946 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 947 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 948 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 949 |  iter 1 / 2 | time 0[s] | loss 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 950 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 951 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 952 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 953 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 954 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 955 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 956 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 957 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 958 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 959 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 960 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 961 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 962 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 963 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 964 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 965 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 966 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 967 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 968 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 969 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 970 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 971 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 972 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 973 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 974 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 975 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 976 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 977 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 978 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 979 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 980 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 981 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 982 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 983 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 984 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 985 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 986 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 987 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 988 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 989 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 990 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 991 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 992 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 993 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 994 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 995 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 996 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 997 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 998 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 999 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 1000 |  iter 1 / 2 | time 0[s] | loss 0.71\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求める単語の分散表現は以下のようになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you [ 0.94134265 -1.5670972   1.0042657  -0.9798423   1.0165973 ]\n",
      "say [-1.1678194 -1.3449364 -0.9423725  1.127167  -1.1367421]\n",
      "goodbye [ 0.96401954 -0.23867942  0.8721969  -0.96921825  0.8614409 ]\n",
      "and [-0.26617897 -1.3233804  -1.8540628   0.81534934 -0.7823937 ]\n",
      "i [ 0.93425214 -0.23797344  0.8558789  -0.9288582   0.84120965]\n",
      "hello [ 0.95631564 -1.5801703   1.0058844  -0.9644152   1.0187151 ]\n",
      ". [-1.5799508 -0.9287598  0.8394477  1.1933532 -1.2130911]\n"
     ]
    }
   ],
   "source": [
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vecに関する補足\n",
    "word2vecを確率の視点で定式化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOWモデルと確率\n",
    "コンテキストとして$w_{t-1}とw_{t+1}$が与えられるとすると，ターゲットの単語が$w_t$になる確率は事後確率の形で，\n",
    "$$ P(w_t | w_{t-1}, w_{t+1}) $$\n",
    "と表現できる．  \n",
    "\n",
    "これを交差エントロピー誤差の式\n",
    "$$ L=-\\sum_{k}t_k log{y_k} $$\n",
    "に当てはめると，教師ラベル$t_k$は$k=t$のときのみ1のone-hotベクトルの要素なので，  \n",
    "$$ L=-log{P(w_t | w_{t-1}, w_{t+1})}$$\n",
    "と，シグマのない形に書き直せる．  \n",
    "この式は**負の対数尤度**と呼ばれる．  \n",
    "\n",
    "さらに，負の対数尤度の式をコーパス全体に拡張し，コーパス内の全単語の誤差の平均，すなわちCBOWの最小化対象となる目的関数は  \n",
    "$$ L=-\\frac{1}{T} \\sum_{t=1}^{T} log{P(w_t | w_{t-1}, w_{t+1})}$$\n",
    "となる．  \n",
    "\n",
    "これはウィンドウサイズが1の場合の目的関数だが，$m$などの他のウィンドウサイズの場合も簡単に表せる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip-gramモデル\n",
    "CBOWモデルとは逆に，ターゲットからコンテキストを推測する．  \n",
    "そのネットワーク構成は，入力層が一つ，出力層が複数になる．  \n",
    "\n",
    "このとき，skip-gramのモデルは以下のようになる．  \n",
    "$$ P(w_{t-1}, w_{t+1} | w_t) $$\n",
    "\n",
    "ここで，skip-gramモデルでは，コンテキストの単語間に関連性がないと仮定(条件付き独立)すると，\n",
    "$$ P(w_{t-1}, w_{t+1} | w_t) = P(w_{t-1} | w_t)P(w_{t+1} | w_t) $$\n",
    "のように変形することができる．  \n",
    "\n",
    "そしてこの式を交差エントロピー誤差に適用すると，\n",
    "$$ L=-log{P(w_{t-1}, w_{t+1} | w_t)}$$\n",
    "$$ = -log{P(w_{t-1} | w_t)P(w_{t+1} | w_t)} $$\n",
    "$$ = -(log{P(w_{t-1} | w_t)} + log{P(w_{t+1} | w_t)}) $$\n",
    "と変形できる．つまり，skip-gramの損失関数はコンテキストごとの損失の総和になる．  \n",
    "\n",
    "さらにこれをコーパス全体に拡張すると，skip-gramの最小化対象となる目的関数は，\n",
    "$$ L=-\\frac{1}{T} \\sum_{t=1}^{T} (log{P(w_{t-1} | w_t)} + log{P(w_{t+1} | w_t)})$$\n",
    "となる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOWとskip-gram，どちらを使うべきか？  \n",
    "skip-gram: 単語の分散表現の精度が高いことが多い(CBOWより問題の難易度が難しいから？)  \n",
    "CBOW: skip-gramはコンテキストの数だけ損失を求めるため，CBOWの方が比較的高速  \n",
    "\n",
    "実装はch3/simple_skip_gram.pyにある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウントベース vs 推論ベース\n",
    "カウントベース(共起行列＋SVD)：　コーパス全体の統計データから1回の学習で単語の分散表現を獲得  \n",
    "推論ベース(CBOW, skip-gramをNNで学習) : コーパスの一部を何度も見ながら学習し，NNの重みを単語の分散表現として獲得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 語彙に新しい単語を追加する場合  \n",
    "カウントベース: 共起行列を作り直し，SVDをもう一度行わなくてはならない  \n",
    "推論ベース： これまでに学習した重みを初期値として再学習すればいい  \n",
    "  \n",
    "  \n",
    "- 分散表現の性質  \n",
    "カウントベース： 単語の類似性がエンコードされる  \n",
    "推論ベース： 特にskip-gramで，単語間のパターンを捉えられる(king - man + woman = queen)のような類推問題を解ける  \n",
    "  \n",
    "  \n",
    "- 精度\n",
    "精度の定量的評価については優劣がつけられないことが報告されている．  \n",
    "「Don't count, predict!」という論文もあれば，単語の類似性に関するタスクではハイパーパラメータの依存度が大きく，優劣がつけられないという報告もある．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skip-gramとNegative Sampling(次章)を利用したモデルは，コーパス全体の共起行列に少し手を加えた行列に対して，特殊は行列分解をしているのと同じであることが示されており，ある条件において推論ベースの手法とカウントベースの手法は繋がっていることがわかっている．  \n",
    "\n",
    "推論ベースとカウントベースの手法を融合させたようなGloVeという手法も提案されている．  \n",
    "具体的には，コーパス全体の統計データの情報を損失関数に取り入れ，ミニバッチ学習をしている．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
